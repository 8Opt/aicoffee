{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "import datasets\n",
    "\n",
    "\n",
    "torch.manual_seed(17)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'labels'],\n",
       "    num_rows: 23410\n",
       "})"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id = \"microsoft/cats_vs_dogs\"\n",
    "\n",
    "dataset = datasets.load_dataset(dataset_id) # -> DatasetDict('train': {..})\n",
    "dataset = dataset.get('train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Helper functions\"\n",
    "def pil_to_tensor(img: Any) -> torch.Tensor: \n",
    "    tensor = v2.functional.pil_to_tensor(img)\n",
    "    return tensor\n",
    "\n",
    "def tensor_to_pil(tensor: torch.Tensor) -> Any: \n",
    "    img = v2.functional.to_image(tensor)\n",
    "    return img    \n",
    "\n",
    "def image_preprocessing(img, size=[224, 224]) -> torch.Tensor: \n",
    "    img = v2.functional.resize(img, size=size)\n",
    "    return img\n",
    "\n",
    "def unique_labels(labels: list) -> dict:\n",
    "    rst = {}\n",
    "    for label in labels:\n",
    "        if label not in rst.keys():\n",
    "            rst[label] = 0\n",
    "        else:\n",
    "            rst[label] += 1\n",
    "\n",
    "    return rst\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatDogDataset(Dataset): \n",
    "    def __init__(\n",
    "            self, \n",
    "            dataset: datasets.Dataset, \n",
    "            is_transform: bool = True, \n",
    "            resize: tuple = (32, 32)): \n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.is_transform = self._transform(resize, is_transform)\n",
    "\n",
    "    def __getitem__(self, idx) -> tuple: \n",
    "        entity = self.dataset[idx]\n",
    "        image = entity.get('image')\n",
    "        image = image.convert(\"L\")    # [1, H, W] :: PIL\n",
    "        tensor = pil_to_tensor(image)           # [..] :: Torch\n",
    "        if self.is_transform: \n",
    "            tensor = self.is_transform(tensor)\n",
    "        labels = entity.get('labels')\n",
    "        return (tensor, labels) \n",
    "    \n",
    "\n",
    "    def __len__(self) -> int: \n",
    "        return len(self.dataset)\n",
    "\n",
    "    @staticmethod\n",
    "    def _transform(resize: tuple, is_transform: bool = True) -> torch.Tensor: \n",
    "        if is_transform: \n",
    "            transformer = v2.Compose([\n",
    "                    v2.RandomResizedCrop(size=resize, antialias=True),\n",
    "                    v2.RandomHorizontalFlip(p=0.5),\n",
    "                    v2.ToDtype(torch.float32, scale=True),\n",
    "                    v2.Normalize(mean=[0.456], std=[0.225]),\n",
    "            ])\n",
    "        else: \n",
    "            transformer = v2.Compose([\n",
    "                v2.Resize(size=resize), \n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(mean=[0.456], std=[0.225]),\n",
    "            ])\n",
    "        return transformer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor those who do not want to use nn.Sigmoid() layer\\nYou can use: torch.sigmoid(self.fc(x))\\n'"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, device: str):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "        self.fc = nn.Sequential([\n",
    "            nn.Linear(input_size, input_size//2), \n",
    "            nn.Linear(input_size//2, num_classes)\n",
    "        ])\n",
    "        self.output = nn.Sigmoid()\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1).to(self.device)  # Flatten the image [C, H, W] -> [C, H * W]\n",
    "        return self.output(self.fc(x))\n",
    "\n",
    "\"\"\"\n",
    "For those who do not want to use nn.Sigmoid() layer\n",
    "You can use: torch.sigmoid(self.fc(x))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Hyperparameters\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "input_size = 32 * 32 * 1  # Image size after resizing (32x32 with 1 channels)\n",
    "patience = 5  # Early stopping patience\n",
    "checkpoint_path = \"./best_model.pth\"  # Path to save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'labels'],\n",
       "    num_rows: 23410\n",
       "})"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_id = \"microsoft/cats_vs_dogs\"\n",
    "\n",
    "dataset = datasets.load_dataset(dataset_id) # -> DatasetDict('train': {..})\n",
    "dataset = dataset.get('train')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "2. Setup dataset => test_size: 0.1\n",
    "train: 80%\n",
    "validate_size: 20%\n",
    "val: 10%\n",
    "test: 10%\n",
    "\"\"\"\n",
    "dataset = dataset.train_test_split(test_size=0.2)   # DatasetDict({'train': {..}, 'test': {..}})\n",
    "train_ds = dataset.get('train')\n",
    "validate_cluster = dataset.get('test')\n",
    "\n",
    "\n",
    "validate_cluster = validate_cluster.train_test_split(test_size=0.5) \n",
    "val_ds = validate_cluster.get('train')\n",
    "test_ds = validate_cluster.get('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Implement Dataset and DataLoader\n",
    "train_dataset = CatDogDataset(dataset=train_ds)\n",
    "val_dataset = CatDogDataset(dataset=val_ds, is_transform=False)\n",
    "test_dataset = CatDogDataset(dataset=test_ds, is_transform=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionModel(\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  (output): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Logistic Regression Model\n",
    "n_classes = 2 # Cat and Dog\n",
    "model = LogisticRegressionModel(input_size=input_size, \n",
    "                                num_classes=n_classes, \n",
    "                                device=device)\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()    # -> BinaryCrossEntropy: the dataset labels will be merged as [0, 1]\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Training Function\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, correct = 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), accuracy\n",
    "\n",
    "# 7. Validation Function\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1. Training Loop\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_acc:.2f}%\\n\")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.2. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Inference test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viscomp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
